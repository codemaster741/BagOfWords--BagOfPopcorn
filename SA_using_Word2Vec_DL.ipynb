{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15ebc7d-f6bc-4c77-b483-3be9c01a19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddbba746-2ed7-4f48-b211-a3e53f295dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data\n",
    "\n",
    "training_data= pd.read_csv('/Users/harikrishnanagarajan/Desktop/Kaggle/SA_using_Word2vec/labeledTrainData.tsv', header= 0, delimiter= '\\t')\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8984da-676f-45bb-bcc1-ce6cd3ed2606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Go immediately and rent this movie. It will be be on a bottom shelf in your local video store and will be covered in dust. No one will have touched it in years. It may even be a $.50 special! It's worth ten bucks, I swear! Buy it! There aren't very many films than can compare with this - the celluloid version of that goo that forms at the bottom of a trash can after a few years. Yes, I gave it a '1,' but it really deserves much lower. 1-10 scales were not designed with stuff like this in mind.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.review[2222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40168876-f72f-44a0-9ccf-9dff959ae9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           0\n",
      "sentiment    0\n",
      "review       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "1    12500\n",
      "0    12500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for null values and balance of data\n",
    "\n",
    "print(training_data.isna().sum())\n",
    "print('\\n')\n",
    "print(training_data.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129feb9-cbf8-40ba-a9ad-6a26294a9da2",
   "metadata": {},
   "source": [
    "### Cleaning the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f4afb2-fab7-4548-9fa2-3e0191c7b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_text(review):\n",
    "    \n",
    "    text= BeautifulSoup(review).get_text()\n",
    "    \n",
    "    letters_only= re.sub(\"[^A-Za-z]\", \" \", text)\n",
    "    \n",
    "    words= letters_only.lower().split()\n",
    "    \n",
    "    stop_words= set(stopwords.words('english'))\n",
    "    \n",
    "    meaningful_words= [x for x in words if x not in stop_words]\n",
    "    \n",
    "    return \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a182332c-72c6-487b-8da4-114257c1dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews= []\n",
    "                         \n",
    "for review in training_data.review:\n",
    "    \n",
    "    clean_reviews.append(clean_raw_text(review))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de8f517-5b20-4d53-9647-fa280444cfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go immediately rent movie bottom shelf local video store covered dust one touched years may even special worth ten bucks swear buy many films compare celluloid version goo forms bottom trash years yes gave really deserves much lower scales designed stuff like mind'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_reviews[2222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a52afa-8bc0-469a-bb41-f03cf5f174bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'immediately', 'rent', 'movie', 'bottom', 'shelf', 'local', 'video', 'store', 'covered', 'dust', 'one', 'touched', 'years', 'may', 'even', 'special', 'worth', 'ten', 'bucks', 'swear', 'buy', 'many', 'films', 'compare', 'celluloid', 'version', 'goo', 'forms', 'bottom', 'trash', 'years', 'yes', 'gave', 'really', 'deserves', 'much', 'lower', 'scales', 'designed', 'stuff', 'like', 'mind']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized= [word_tokenize(review) for review in clean_reviews]\n",
    "\n",
    "print(tokenized[2222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e48cf713-06e7-4097-a057-833b9e9601b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 128\n",
    "context_size = 5\n",
    "min_word = 1\n",
    "\n",
    "word_vec= Word2Vec(tokenized, vector_size=feature_size, window=context_size, min_count=min_word, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f48daf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('film', 1)\n",
      "(74066, 128)\n"
     ]
    }
   ],
   "source": [
    "word_vec_unpack = [(word, idx) for word, idx in \\\n",
    "                   word_vec.wv.key_to_index.items()]\n",
    "vocab= len(word_vec_unpack) + 2\n",
    "print(word_vec_unpack[1])\n",
    "embedding_matrix= np.zeros((vocab, 128))\n",
    "for word, i in word_vec_unpack:\n",
    "    embedding_matrix[i]= word_vec.wv[i]\n",
    "    \n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e29520b8-0b3e-4299-8114-ab48411b7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X= np.array(clean_reviews)\n",
    "y= np.array(training_data.sentiment)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid= train_test_split(X, y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddf0d2e6-314e-40d0-be85-1b3ea471c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer= Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "sequence_length= 100\n",
    "\n",
    "X_train_padded= pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen= sequence_length, padding= 'post')\n",
    "X_valid_padded= pad_sequences(tokenizer.texts_to_sequences(X_valid), maxlen= sequence_length, padding= 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f229b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, GlobalMaxPool1D, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional, SimpleRNN, GRU\n",
    "from keras import utils\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba5153cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 100, 128)          9480448   \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 100, 60)           38160     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 9,520,469\n",
      "Trainable params: 9,520,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "\n",
    "model.add(Embedding(vocab, 128, weights= [embedding_matrix], input_length= sequence_length))\n",
    "model.add(Bidirectional(LSTM(30, activation= 'relu', return_sequences= True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(30, activation= 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer= Adam(learning_rate= 0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2732e222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 31s 166ms/step - loss: 0.7330 - accuracy: 0.6069 - val_loss: 0.4535 - val_accuracy: 0.7920\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.4053 - accuracy: 0.8166 - val_loss: 0.4062 - val_accuracy: 0.8150\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.3094 - accuracy: 0.8692 - val_loss: 0.3816 - val_accuracy: 0.8316\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 29s 184ms/step - loss: 0.2240 - accuracy: 0.9154 - val_loss: 0.3995 - val_accuracy: 0.8246\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1597 - accuracy: 0.9439 - val_loss: 0.4413 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f801c540dd0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train, validation_data=(X_valid_padded, y_valid), epochs= 5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83595470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data= pd.read_csv('/Users/harikrishnanagarajan/Desktop/Kaggle/SA_using_Word2vec/testData.tsv', delimiter= '\\t')\n",
    "\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2537e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        0\n",
      "review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking test data for null values\n",
    "\n",
    "print(testing_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8b8c3552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naturally film main themes mortality nostalgia loss innocence perhaps surprising rated highly older viewers younger ones however craftsmanship completeness film anyone enjoy pace steady constant characters full engaging relationships interactions natural showing need floods tears show emotion screams show fear shouting show dispute violence show anger naturally joyce short story lends film ready made structure perfect polished diamond small changes huston makes inclusion poem fit neatly truly masterpiece tact subtlety overwhelming beauty'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_reviews= [clean_raw_text(review) for review in testing_data.review]\n",
    "\n",
    "cleaned_test_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ccefda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded= pad_sequences(tokenizer.texts_to_sequences(cleaned_test_reviews), maxlen= sequence_length, padding= 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "105ceda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "predictions= model.predict(X_test_padded)\n",
    "\n",
    "temp= list(itertools.chain.from_iterable(predictions))\n",
    "results= [round(num, 0) for num in temp]\n",
    "output = pd.DataFrame( data={\"id\":testing_data[\"id\"], \"sentiment\":results} )\n",
    "output.to_csv('submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47149812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
